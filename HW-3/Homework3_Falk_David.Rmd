
---
title: "Homework 3"
author: "David Falk"
date: "`r Sys.time()`"
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes
---
<!---
In order to check that all the necessary packages are installed, Click the File > New File > R Markdown button and keep all of the options as is. Save the document somewhere, and, while that new document is open, click the knit button. If a window with some plots shows up, everything is installed correctly. If RStudio prompts you to install any packages, you should install them.
-->

<!---
Please save this file as Homework3_lastname_firstname.Rmd

Be sure to update the author field in the block above.

While you are working on your homework, you can use the green arrows to run a "chunk" of code. In order to produce the final document, use the knit button. You will turn in both the Rmd file and the knitted html file, which will appear next to wherever you saved the Rmd file if there are no errors.

Beware, if you run chunks out of order or reuse variable names your code may produce different results when it is run again from top to bottom. Before you knit your document, it is a good idea to run all the chunks in order from top to bottom in a clean environment. Use the broom button in the environment pane to clear your variables and click the Session > Restart R and Run All Chunks.

If you ever want to reference the documentation about a function, go to the console below and type ?function_name.
-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
# Can set your local path to control exactly where this saves. Otherwise, will save in directory with the Rmd file
# knitr::opts_knit$set(root.dir = "/home/expdes/outputs/")  

library(tidyverse)  # hub of many packages
set.seed(1)  # reproducible results
theme_set(theme_minimal())  # nice-looking plots

```

# Part 0: Importing Data  
Import the class data from Canvas.  
```{r}

# Loading the CSVs
class_data <- read.csv(file.path("data", "class_data.csv"))
participant_level_data <- read.csv(file.path("data", "participant_level_data.csv"))

# Pre extract relevant columns
vviq_scores        <- participant_level_data$VVIQ_score
trueRecall_scores  <- participant_level_data$true_recall_proportion
falseRecall_scores <- participant_level_data$false_recall_proportion
```


   
# Part 1: Simple Linear Regression  

One question we have is whether imagery ability predicts memory performance (both true recall and false recall). will use a Simple Linear Regression to answer these questions, and we will start off using the `participant_level_data` first.  

## Question 1: Create two scatterplots: (4 points total)  

a. Plot VVIQ_score (x-axis) by true recall proportion (y-axis) for each participant. Be sure to title and label your plot appropriately and to use jitter if necessary.

```{r}

# Plot vviq by true recall
plot(
     vviq_scores,
     jitter(trueRecall_scores),
     col = "darkgreen",
     pch = 16,
     xlab = "VVIQ Score",
     ylab = "True Recall Proportion",
     xlim = c(0, max(vviq_scores)),
     ylim = c(0, 1),
     main = "True Recall Proportion Against VVIQ Score"
)
```

b. Plot VVIQ_score (x-axis) by false recall proportion (y-axis) for each participant. Be sure to title and label your plot appropriately and to use jitter if necessary.

```{r}
# Plot vviq by false recall
plot(
     vviq_scores,
     jitter(falseRecall_scores),
     col = "maroon",
     pch = 16,
     xlab = "VVIQ Score",
     ylab = "False Recall Proportion",
     xlim = c(0, max(vviq_scores)),
     ylim = c(0, 1),
     main = "False Recall Proportion Against VVIQ Score"
)
```
  
## Question 2:  
Calculate the slope (called m) and intercept (called b) of the best fit line for each scatterplot from scratch.

For each scatterplot, calculate and save the slopes (m)  and intercepts (b) into two dataframes as specified below. Output these dataframes.

Create “coefs_truerecall” with one row and two columns. The columns should be called “m_truerecall” and “b_truerecall” and should contain the slope and intercept values (respectively) for “true_recall_proportion”.
```{r}
bestfit_line = function(x_col, y_col, m_name, b_name) {
  
  # Get means
  mean_x <- mean(x_col)
  mean_y <- mean(y_col)
  
  # Get difference from means
  x_diff <- x_col - mean_x
  y_diff <- y_col - mean_y
  
  # calculate m and b
  m <- sum(x_diff * y_diff) / sum(x_diff ^ 2)
  b <- mean_y - (m * mean_x)
  
  bestfit <- data.frame(m, b)
  names(bestfit) <- c(m_name, b_name)
  return(bestfit)
}

coefs_truerecall <- bestfit_line(vviq_scores, trueRecall_scores, 
                                 "m_truerecall", "b_truerecall")
# Print the data
knitr::kable(
  coefs_truerecall,
  caption = "Line of Best Fit Data (True Recall)"
)
```
  
Create “coefs_falserecall” with one row and two columns. The columns should be called “m_falserecall” and “b_falserecall” and should contain the slope and intercept values (respectively) for “false_recall_proportion”.
```{r}
coefs_falserecall <- bestfit_line(vviq_scores, falseRecall_scores, 
                                 "m_falserecall", "b_falserecall")
# Print the data
knitr::kable(
  coefs_falserecall,
  caption = "Line of Best Fit Data (False Recall)"
)
```


### 2.a:  
Using your slope and intercept, plot the best fit line on top of the previous plot. Be sure to extend your plot boundaries to show the intercept.
```{r}
# Plot vviq by true recall
plot(
     vviq_scores,
     jitter(trueRecall_scores),
     col = "darkgreen",
     pch = 16,
     xlab = "VVIQ Score",
     ylab = "True Recall Proportion",
     xlim = c(0, max(vviq_scores)),
     ylim = c(min(0, coefs_truerecall$b_truerecall), 1),
     main = "True Recall Proportion Against VVIQ Score"
)
abline(a = coefs_truerecall$b_truerecall[1],
       b = coefs_truerecall$m_truerecall[1],
       col = "orange",
       lwd = 3)
```
  
```{r}
plot(
     vviq_scores,
     jitter(falseRecall_scores),
     col = "maroon",
     pch = 16,
     xlab = "VVIQ Score",
     ylab = "False Recall Proportion",
     xlim = c(0, max(vviq_scores)),
     ylim = c(min(0, coefs_falserecall$b_falserecall), 1),
     main = "False Recall Proportion Against VVIQ Score"
)
abline(a = coefs_falserecall$b_falserecall[1],
       b = coefs_falserecall$m_falserecall[1],
       col = "orange",
       lwd = 3)
```


### 2.b:  
For each best fit line, write the linear function in slope-intercept form.
True Recall:  y =  0.0002886189 * x + 0.5168375
False Recall: y = -0.0036113260 * x + 0.5483042

  
### 2.c:  
For each scatterplot, briefly discuss: Visually looking at this best fit line, what can you describe about the slope and the relationship between these two variables? How does y change as you increase 1 unit in x?

For true recall proportion there is a nearly flat (ever so slightly positive slope) relationship between VVIQ score and true recall proportion. This implies that modulating VVIQ score has very little effect on true recall proportion. As you increase one unit along the x axis (vviq score) you see a change of 0.0002886189 along the y axis (true recall proportion).  

For false recall proportion there is a negative relationship between VVIQ score and false recall proportion As you increase one unit along the x axis (vviq score) you see a change of -0.0036113260 along the y axis (false recall proportion).  

  
## Question 3:  
For each comparison, calculate the residuals.

Create a new dataframe from `participant_level_data` called “truerecall_resid_bestfit” that contains the residuals of the model using “VVIQ_score” to predict “true_recall_proportion”. Output the first ten rows of the dataframe.   
```{r}
calculate_residuals = function(x_col, y_col, coefs) {
  
  # Extract slope and intercept from coefficients
  m <- coefs[1, 1]
  b <- coefs[1, 2]
  
  # Calculate predicted values for x column
  pred_vals <- (m * x_col) + b
  
  # Get residuals
  residuals <- data.frame(residuals = y_col - pred_vals)
  
  return(residuals)
}

truerecall_resid_bestfit <- calculate_residuals(vviq_scores, trueRecall_scores, coefs_truerecall)

# Print the data
knitr::kable(
  head(truerecall_resid_bestfit, 10),
  caption = "True Recall Residuals (First 10 Rows)"
)
```
  
Create a new dataframe from `participant_level_data` called “falserecall_resid_bestfit” that contains the residuals of the model using “VVIQ_score” to predict “false_recall_proportion”. Output the first ten lines of the dataframe. 
```{r}
falserecall_resid_bestfit <- calculate_residuals(vviq_scores, falseRecall_scores, coefs_falserecall)

# Print the data
knitr::kable(
  head(falserecall_resid_bestfit, 10),
  caption = "False Recall Residuals (First 10 Rows)"
)
```

  
For each best fit line, create a residuals plot.
```{r}
overall_min_resid <- min(min(truerecall_resid_bestfit$residuals), min(falserecall_resid_bestfit$residuals))
overall_max_resid <- max(max(truerecall_resid_bestfit$residuals), max(falserecall_resid_bestfit$residuals))
plot(
     vviq_scores,
     jitter(truerecall_resid_bestfit$residuals),
     col = "orange",
     pch = 16,
     xlab = "VVIQ Score",
     ylab = "Residual",
     xlim = c(0, max(vviq_scores)),
     ylim = c(overall_min_resid, overall_max_resid),
     main = "True Recall Residuals Against VVIQ Score"
)
```
  
```{r}
plot(
     vviq_scores,
     jitter(falserecall_resid_bestfit$residuals),
     col = "maroon",
     pch = 16,
     xlab = "VVIQ Score",
     ylab = "Residual",
     xlim = c(min(vviq_scores), max(vviq_scores)),
     ylim = c(overall_min_resid, overall_max_resid),
     main = "False Recall Residuals Against VVIQ Score"
)
```

  
For each residual plot, briefly discuss: Do you see any patterns here? What does this mean about the linear fit, based on what you do/don’t see in the residuals? 

True recall residuals:
The residuals seem to be randomly scattered around zero with roughly constant spread across VVIQ scores. There isn't a clear pattern or curvature. This suggests that the linear model is appropriate and that assumptions about linearity and homoskedasticity are reasonably satisfied.

False recall residuals:
The residuals are more variable and may there might be an effect of VVIQ score on residual, particularly at higher values. This could mean mild heteroskedasticity or a potential nonlinear relationship. However, there is no strong systematic pattern, so I think that the linear model is still reasonable, though the fit appears weaker than for true recall.



## Question 4:
Calculate the best fit lines using a built-in R function. 
```{r}
# Best fit line for VVIQ & true recall proportion

# Get initial values (apparently not a dataframe)
builtin_true  <- lm(trueRecall_scores ~ vviq_scores)

# Convert data to dataframes
builtin_coefs_truerecall  <- data.frame(
                        m_truerecall = builtin_true$coefficients[2],
                        b_truerecall = builtin_true$coefficients[1])

# Log the results in line and equation form
knitr::kable(
  builtin_coefs_truerecall,
  caption = "Line of Best Fit Data (True Recall)"
)
cat(sprintf("True Recall Line of Best Fit: y = %.6f * x + %.6f", builtin_coefs_truerecall$m_truerecall, builtin_coefs_truerecall$b_truerecall)
)
```
  
```{r}
# Best fit line for VVIQ & false recall proportion

# Get initial values (apparently not a dataframe)
builtin_false <- lm(falseRecall_scores ~ vviq_scores)

# Convert data to dataframes
builtin_coefs_falserecall <- data.frame(
                        m_falserecall = builtin_false$coefficients[2],
                        b_falserecall = builtin_false$coefficients[1])

# Log the results in table and equation form
knitr::kable(
  builtin_coefs_falserecall,
  caption = "Line of Best Fit Data (False Recall)"
)
cat(sprintf("False Recall Line of Best Fit: y = %.6f * x + %.6f", builtin_coefs_falserecall$m_falserecall, builtin_coefs_falserecall$b_falserecall)
)
```

How do these lines compare to the ones you calculated from scratch?
The values for my function and the built-in function are identical.


  

# Part 2: Multiple Regression    
  
## Question 5:  
Now we can finally put all the pieces together from the experiment to answer one of our main questions! Essentially: how do encoding strategy, interference type, and imagery ability impact memory performance? Let’s try testing this out with a multiple regression! We will now turn to using the `class_data` (because we want to use some within subjects factors here).    

Standardize all variables before including them in your regression. Add the standardized variables to “class_data” and call them “true_recall_proportion_z” and “vviq_z”. Output the first 10 rows of “class_data”.
```{r}

# Get z scored data for true recall and vviq
# (seemed safest to calculate by hand)
true_recall_proportion_z <- (trueRecall_scores - mean(trueRecall_scores)) / sd(trueRecall_scores) 
vviq_z <- (vviq_scores - mean(vviq_scores)) / sd(vviq_scores)


# Add values to class data
class_data$true_recall_proportion_z <- true_recall_proportion_z
class_data$vviq_z <- vviq_z
```

Using R built-in functions, calculate the multiple linear regression fit for a model with the following variables. Call this model "fit".  Output the summary of the model.  

Variables:  
a. Encoding strategy as a categorical IV (as 4 categories).  
b. Interference type as a categorical IV.  
c. VVIQ score as a continuous IV.  
d. True recall performance as a continuous DV.    
```{r}
#fit
```


  
## Question 6:  
Report the best fit plane function from Question 5.
*Please write your response in the lines below.* 


  
## Question 7:  
Write code that partitions the variance by doing the following steps (parts a-c):

*HINT - Continue to use the standardized variables when computing the SSE and onwards*

### 7.a:  
Calculate the sum of square errors (SSE) from scratch. Save this in a variable called “SSE” and output the value.
```{r}
#SSE
```

  
### 7.b:  
Calculate the sum of square regression (SSR) from scratch. Save this in a variable called “SSR” and output the value. 
```{r}
#SSR
```

  
  
### 7.c:  
Calculate the sum of square total (SST) from scratch. Save this in a variable called “SST” and output the value.
```{r}
#SST
```
  
  
## Question 8:  
Briefly describe: What do these variance components tell us about the amount of variance explained by the regression?
*Please write your response in the lines below.* 



## Question 9:  
Write code that further partitions the variance using a reduced model. Show these calculations from scratch.

### 9.a:  
How much of the SSR is unique to encoding strategy? Call this variable “UniqueSSR_encoding_strategy” and output the value.
```{r}
#UniqueSSR_encoding_strategy
```

  
### 9.b:  
How much of the SSR is unique to VVIQ score? Call this variable “UniqueSSR_vviq” and output the value. 
```{r}
#UniqueSSR_vviq
```
  
### 9.c:  
How much of the SSR is shared between these two factors? Call this variable “Shared_SSR” and output the value. 
```{r}
#Shared_SSR
```
  
  
  
## Question 10: 

### 10.a:  
Calculate R^2 goodness of fit **from scratch**. Save this in a variable called “Rsq” and output the value.
```{r}
#Rsq
```

  
### 10.b:  
Calculate Adjusted R^2 **from scratch**. Save this in a variable called “Adj_Rsq” and output the value. 
```{r}
#Adj_Rsq
```

Briefly discuss how the relationship between R^2 and Adjusted R^2 here relates to the ideal number of predictors in the model. 
*Please write your response in the lines below.* 

  
### 10.c:  
Calculate Cohen’s f2 for effect size **from scratch**. Save this in a variable called “cohen_fsq” and output the value.
```{r}
#cohen_fsq
```
  
  
### 10.d:  
Calculate the F-statistic and corresponding p-value for overall model significance **from scratch**. Save these in separate variables called “F_stat” and “pval_F” and output these values.
```{r}
#F_stat
#pval_F
```


  
## Question 11:  
Calculate these metrics using built-in R functions and and report those here. 
```{r}

```


Additionally, calculate t-statistics and corresponding p-values for each predictor using built-in R functions.  
```{r}
#t_stat
#pval_t
```


## Question 12:  
Report all of the calculated information from the multiple regression as if reporting in a research paper.
*Please write your response in the lines below.*  



  
## Question 13:  
Re-run the model with a random effect of participant added. (Now you have a mixed effects model!). You can use built-in functions for this. Run your "model_updated".   

```{r}
#model_updated
```


### 13.a:  
Describe why we would include a random effect of participant.   
*Please write your response in the lines below.* 

  
### 13.b:  
Report the best fit plane function of your new model.
*Please write your response in the lines below.* 


### 13.c:  
Calculate (using built-in functions is fine) the beta, t-statistic, Standard Error (SE) for each predictor and their p-values.   

*Hint: Since the standard lmer function does not provide p-values by default, we recommend using the lmerTest package. Simply loading it with library(lmerTest) before running your model will automatically add p-values to your summary() output.*  

```{r}

``` 
  
### 13.d:  
Report the results (computed in 13.c)  as if reporting in a research paper.
*Please write your response in the lines below.* 




### 13.e:  
Briefly discuss: How did your change(s) impact the weight of each predictor?
*Please write your response in the lines below.* 



